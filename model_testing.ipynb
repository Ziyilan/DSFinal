{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "# We can use the pandas library in python to read in the csv file.\n",
    "# This creates a pandas dataframe and assigns it to the titanic variable.\n",
    "titanic = pandas.read_csv(\"datasets/train.csv\")\n",
    "\n",
    "# print titanic.describe()\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "titanic[\"Age\"] = titanic[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "titanic.loc[titanic[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "titanic.loc[titanic[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna(\"S\")\n",
    "titanic.loc[titanic[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "titanic.loc[titanic[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "titanic.loc[titanic[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
    "\n",
    "# This creates a pandas dataframe and assigns it to the titanic variable.\n",
    "titanic_test = pandas.read_csv(\"datasets/test.csv\")\n",
    "\n",
    "# Fill in all NaN ages with the median age from the train dataset.\n",
    "titanic_test[\"Age\"] = titanic_test[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "\n",
    "# Replace all the occurences of male with the number 0 and all the occurences of female with the number 1.\n",
    "titanic_test.loc[titanic_test[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "titanic_test.loc[titanic_test[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "\n",
    "# Replace all of the missing values with \"S\".\n",
    "titanic_test[\"Embarked\"] = titanic_test[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "# Replace all of the code letters with their corresponding code integer values.\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
    "\n",
    "# Fill in all NaN ages with the median Fare from the test dataset.\n",
    "titanic_test[\"Fare\"] = titanic_test[\"Fare\"].fillna(titanic_test[\"Fare\"].median())\n",
    "\n",
    "# Initialize our algorithm with the default paramters\n",
    "# n_estimators is the number of trees we want to make\n",
    "# min_samples_split is the minimum number of rows we need to make a split\n",
    "# min_samples_leaf is the minimum number of samples we can have at the place where a tree branch ends \n",
    "# (the bottom points of the tree)\n",
    "\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=4, min_samples_leaf=2)\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "\n",
    "# Generating a familysize column\n",
    "# titanic[\"FamilySize\"] = titanic[\"SibSp\"] + titanic[\"Parch\"]\n",
    "\n",
    "# The .apply method generates a new series\n",
    "# titanic[\"NameLength\"] = titanic[\"Name\"].apply(lambda x: len(x))\n",
    "\n",
    "import re\n",
    "\n",
    "# A function to get the title from a name.\n",
    "def get_title(name):\n",
    "    # Use a regular expression to search for a title.  Titles always consist of capital and lowercase letters, and end with a period.\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "# Get all the titles and print how often each one occurs.\n",
    "# titles = titanic[\"Name\"].apply(get_title)\n",
    "# print(pandas.value_counts(titles))\n",
    "\n",
    "# Map each title to an integer.  Some titles are very rare, and are compressed into the same codes as other titles.\n",
    "# title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2}\n",
    "# for k,v in title_mapping.items():\n",
    "#     titles[titles == k] = v\n",
    "\n",
    "# Verify that we converted everything.\n",
    "#print(pandas.value_counts(titles))\n",
    "\n",
    "# Add in the title column.\n",
    "# titanic[\"Title\"] = titles\n",
    "\n",
    "import operator\n",
    "\n",
    "# A dictionary mapping family name to id\n",
    "family_id_mapping = {}\n",
    "\n",
    "# A function to get the id given a row\n",
    "def get_family_id(row):\n",
    "    # Find the last name by splitting on a comma\n",
    "    last_name = row[\"Name\"].split(\",\")[0]\n",
    "    # Create the family id\n",
    "    family_id = \"{0}{1}\".format(last_name, row[\"FamilySize\"])\n",
    "    # Look up the id in the mapping\n",
    "    if family_id not in family_id_mapping:\n",
    "        if len(family_id_mapping) == 0:\n",
    "            current_id = 1\n",
    "        else:\n",
    "            # Get the maximum id from the mapping and add one to it if we don't have an id\n",
    "            current_id = (max(family_id_mapping.items(), key=operator.itemgetter(1))[1] + 1)\n",
    "        family_id_mapping[family_id] = current_id\n",
    "    return family_id_mapping[family_id]\n",
    "\n",
    "# Get the family ids with the apply method\n",
    "# family_ids = titanic.apply(get_family_id, axis=1)\n",
    "\n",
    "# There are a lot of family ids, so we'll compress all of the families under 3 members into one code.\n",
    "# family_ids[titanic[\"FamilySize\"] < 3] = -1\n",
    "\n",
    "# Print the count of each unique id.\n",
    "# print(pandas.value_counts(family_ids))\n",
    "\n",
    "# titanic[\"FamilyId\"] = family_ids\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"SibSp\", \"Parch\"]#, \"FamilySize\", \"Title\", \"FamilyId\"]\n",
    "\n",
    "# Perform feature selection\n",
    "#selector = SelectKBest(f_classif, k=5)\n",
    "#selector.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "\n",
    "# Get the raw p-values for each feature, and transform from p-values into scores\n",
    "#scores = -np.log10(selector.pvalues_)\n",
    "\n",
    "# Plot the scores.  See how \"Pclass\", \"Sex\", \"Title\", and \"Fare\" are the best?\n",
    "#plt.bar(range(len(predictors)), scores)\n",
    "#plt.xticks(range(len(predictors)), predictors, rotation='vertical')\n",
    "#plt.show()\n",
    "\n",
    "# Pick only the four best features.\n",
    "#predictors = [\"Pclass\", \"Sex\", \"Fare\", \"Title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn accuracy: 0.818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsutker/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:26: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n"
     ]
    }
   ],
   "source": [
    "alg = RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=8, min_samples_leaf=4)\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "\n",
    "# Initialize the cross validation folds\n",
    "kf = KFold(titanic.shape[0], n_folds=3, random_state=1)\n",
    "\n",
    "predictions = []\n",
    "for train, test in kf:\n",
    "    train_target = titanic[\"Survived\"].iloc[train]\n",
    "    full_test_predictions = []\n",
    "    # Make predictions for each algorithm on each fold\n",
    "    # Fit the algorithm on the training data.\n",
    "    alg.fit(titanic[predictors].iloc[train,:], train_target)\n",
    "    # Select and predict on the test fold.  \n",
    "    # The .astype(float) is necessary to convert the dataframe to all floats and avoid an sklearn error.\n",
    "    test_predictions = alg.predict_proba(titanic[predictors].iloc[test,:].astype(float))[:,1]\n",
    "    # Any value over .5 is assumed to be a 1 prediction, and below .5 is a 0 prediction.\n",
    "    test_predictions[test_predictions <= .5] = 0\n",
    "    test_predictions[test_predictions > .5] = 1\n",
    "    predictions.append(test_predictions)\n",
    "\n",
    "# Put all the predictions together into one array.\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "# print predictions\n",
    "# Compute accuracy by comparing to the training data.\n",
    "accuracy = sum(predictions[predictions == titanic[\"Survived\"]]) / len(predictions)\n",
    "print \"Sklearn accuracy: \" + str(accuracy)\n",
    "\n",
    "# for i in range(len(predictions)):\n",
    "#    if predictions[i] < .5:\n",
    "#        predictions[i] = 0\n",
    "#    else:\n",
    "#        predictions[i] = 1\n",
    "# predictions = predictions.astype(int)\n",
    "# submission = pandas.DataFrame({\n",
    "#        \"PassengerId\": titanic_test[\"PassengerId\"],\n",
    "#        \"Survived\": predictions\n",
    "#    })\n",
    "\n",
    "# Output to a csv for submission.\n",
    "# submission.to_csv(\"kaggle.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting tree 1\n",
      "0.306818181818\n",
      "0.477064220183\n",
      "0.389830508475\n",
      "0.68085106383\n",
      "0.862068965517\n",
      "0.666666666667\n",
      "0.327044025157\n",
      "0.51724137931\n",
      "0.5\n",
      "0.0\n",
      "finished tree 1\n",
      "starting tree 2\n",
      "0.329545454545\n",
      "0.979591836735\n",
      "0.282377919321\n",
      "0.466431095406\n",
      "finished tree 2\n",
      "starting tree 3\n",
      "0.345394736842\n",
      "0.409756097561\n",
      "0.694915254237\n",
      "0.5\n",
      "0.375\n",
      "0.0\n",
      "finished tree 3\n",
      "starting tree 4\n",
      "0.198130841121\n",
      "0.0\n",
      "0.8\n",
      "0.774193548387\n",
      "0.591549295775\n",
      "0.38961038961\n",
      "finished tree 4\n",
      "starting tree 5\n",
      "0.175742574257\n",
      "0.805555555556\n",
      "0.0\n",
      "0.406593406593\n",
      "0.408695652174\n",
      "0.694915254237\n",
      "0.4\n",
      "0.0\n",
      "0.0\n",
      "finished tree 5\n",
      "starting tree 6\n",
      "0.188908145581\n",
      "0.742038216561\n",
      "finished tree 6\n",
      "starting tree 7\n",
      "0.188908145581\n",
      "0.968085106383\n",
      "0.655813953488\n",
      "0.0\n",
      "0.5\n",
      "0.0\n",
      "finished tree 7\n",
      "starting tree 8\n",
      "0.345394736842\n",
      "0.496453900709\n",
      "0.307692307692\n",
      "0.0\n",
      "0.866666666667\n",
      "0.508771929825\n",
      "finished tree 8\n",
      "starting tree 9\n",
      "0.383838383838\n",
      "finished tree 9\n",
      "starting tree 10\n",
      "0.371900826446\n",
      "0.135359116022\n",
      "0.22641509434\n",
      "0.0731707317073\n",
      "0.968085106383\n",
      "0.712\n",
      "0.576086956522\n",
      "0.0\n",
      "finished tree 10\n",
      "starting tree 11\n",
      "0.383838383838\n",
      "finished tree 11\n",
      "starting tree 12\n",
      "0.384269662921\n",
      "0.0\n",
      "finished tree 12\n",
      "starting tree 13\n",
      "0.62962962963\n",
      "0.0\n",
      "0.438596491228\n",
      "0.4\n",
      "0.735294117647\n",
      "0.22009569378\n",
      "0.375\n",
      "0.0\n",
      "finished tree 13\n",
      "starting tree 14\n",
      "0.383838383838\n",
      "finished tree 14\n",
      "starting tree 15\n",
      "0.345394736842\n",
      "0.487084870849\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "finished tree 15\n",
      "starting tree 16\n",
      "0.56204379562\n",
      "0.132911392405\n",
      "0.0666666666667\n",
      "0.708333333333\n",
      "0.724137931034\n",
      "0.466431095406\n",
      "finished tree 16\n",
      "starting tree 17\n",
      "0.383838383838\n",
      "finished tree 17\n",
      "starting tree 18\n",
      "0.383292383292\n",
      "0.4\n",
      "0.5\n",
      "1.0\n",
      "0.0\n",
      "finished tree 18\n",
      "starting tree 19\n",
      "0.383838383838\n",
      "finished tree 19\n",
      "starting tree 20\n",
      "0.188908145581\n",
      "0.741007194245\n",
      "0.75\n",
      "finished tree 20\n",
      "starting tree 21\n",
      "0.56204379562\n",
      "0.132911392405\n",
      "0.708333333333\n",
      "0.471698113208\n",
      "0.5\n",
      "0.414285714286\n",
      "0.0\n",
      "finished tree 21\n",
      "starting tree 22\n",
      "0.383838383838\n",
      "finished tree 22\n",
      "starting tree 23\n",
      "0.62962962963\n",
      "0.140969162996\n",
      "0.655813953488\n",
      "0.0\n",
      "0.25\n",
      "0.0\n",
      "finished tree 23\n",
      "starting tree 24\n",
      "0.340619307832\n",
      "0.471698113208\n",
      "0.41095890411\n",
      "0.0\n",
      "finished tree 24\n",
      "starting tree 25\n",
      "0.62962962963\n",
      "0.472826086957\n",
      "0.243298969072\n",
      "0.2\n",
      "0.0\n",
      "finished tree 25\n"
     ]
    }
   ],
   "source": [
    "from RandomForestRegressor import RandomForestRegressor\n",
    "rfr = RandomForestRegressor(titanic, \"Survived\", n_trees=25, max_depth=5, predictors=predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    418.000000\n",
       "mean       0.388870\n",
       "std        0.097339\n",
       "min        0.264251\n",
       "25%        0.297231\n",
       "50%        0.376369\n",
       "75%        0.481155\n",
       "max        0.578086\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = rfr.predict(titanic_test)\n",
    "predictions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(predictions)):\n",
    "   if predictions[i] < .5:\n",
    "       predictions[i] = 0\n",
    "   else:\n",
    "       predictions[i] = 1\n",
    "predictions = predictions.astype(int)\n",
    "submission = pandas.DataFrame({\n",
    "       \"PassengerId\": titanic_test[\"PassengerId\"],\n",
    "       \"Survived\": predictions\n",
    "   })\n",
    "\n",
    "# Output to a csv for submission.\n",
    "submission.to_csv(\"kaggle25.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It works!!!\n",
    "We tried our algorithm with 5 trees in the forest, and we were able to get approximately 71.77% accuracy. While this is good, it's not quite as good as the sklearn random forest. When we upped it to 20 trees, we got approximately 74.641% accuracy. At 25 trees, we got approximately 75.598% accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
